{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbc49781-d256-478c-ae03-e24c115f2f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cga_utils\n",
    "import prompt_versions_g3\n",
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05f0ee5c-b845-47e2-b782-14afdff3ecbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache\n",
    "from langchain_community.cache import SQLiteCache\n",
    "\n",
    "set_llm_cache(SQLiteCache(database_path=\".langchain.v18_gemma3.db\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19fde62c-77f2-4e79-83cd-4fb22d5031d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "llm = ChatOllama(model=\"gemma3:4b\", temperature = 0.0, top_p = 1, repeat_penalty=1, presence_penalty=0, frequency_penalty=0)  # vagy bármely más elérhető Ollama modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02982f67-59da-4c17-810d-1d2fb2d27e4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "messages = prompt_versions_g3.prompt_versions['V22']\n",
    "messages2 = prompt_versions_g3.prompt_versions['V21'].copy()\n",
    "messages2[-1] = ( messages2[-1][0],  messages2[-1][1] + \" \" )\n",
    "\n",
    "messages3 = prompt_versions_g3.prompt_versions['V21'].copy()\n",
    "messages3[-1] = ( messages3[-1][0],  messages3[-1][1] + \"  \" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f84ea2b-8c8b-4cdc-8eee-b724b08ddb82",
   "metadata": {},
   "source": [
    "## Calc fix performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72802b74-e927-4b3f-8dff-e5bad835bed2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CGA_TRACE_RESP\"] = 'True'\n",
    "\n",
    "rd1 = cga_utils.calc_fix_mcnemar_performance(llm, messages, 'res/gemma3_v19a.csv', 'res/errors_19a_cv1_2_1.csv', trace_messages = True, error_cluster_id=60)\n",
    "rd2 = cga_utils.calc_fix_mcnemar_performance(llm, messages2, 'res/gemma3_v19a.csv', 'res/errors_19a_cv1_2_1.csv', trace_messages = True, error_cluster_id=60)\n",
    "rd3 = cga_utils.calc_fix_mcnemar_performance(llm, messages3, 'res/gemma3_v19a.csv', 'res/errors_19a_cv1_2_1.csv', trace_messages = True, error_cluster_id=60)\n",
    "\n",
    "print(rd1,\"\\n\" ,rd2,\"\\n\" , rd3)\n",
    "print((rd1.summary[\"b_improved\"]+rd2.summary[\"b_improved\"]+rd3.summary[\"b_improved\"])/3, (rd1.summary[\"delta_pp\"]+rd2.summary[\"delta_pp\"]+rd3.summary[\"delta_pp\"])/3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fddeee8-32c3-4124-8b19-97d91c5abd11",
   "metadata": {},
   "source": [
    "## Calc global Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544997ed-17c4-4848-91da-296fb2fb73b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res1 = cga_utils.execute_dataset_predictions(llm, messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc141cbe-9b67-40f4-b290-624e330dda10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res2 = cga_utils.execute_dataset_predictions(llm, messages2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c46a14-83e9-46f4-9b4a-c543f5f3ac26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res3 = cga_utils.execute_dataset_predictions(llm, messages3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d375ad-e0f7-4018-a8ed-a8110d22e927",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_results1 = cga_utils.annotate_results(res1)\n",
    "annotated_results2 = cga_utils.annotate_results(res2)\n",
    "annotated_results3 = cga_utils.annotate_results(res3)\n",
    "#annotated_results.to_csv('res/Ollama_2_gemma3n_e4b_code_values_v11_m1.csv')#\n",
    "#cga_utils.calc_overall_value_match(annotated_results)\n",
    "em1 = cga_utils.calc_overall_em(annotated_results1)\n",
    "em2 = cga_utils.calc_overall_em(annotated_results2)\n",
    "em3 = cga_utils.calc_overall_em(annotated_results3)\n",
    "\n",
    "em = (em1+em2+em3 )/3 \n",
    "em, em1, em2, em3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f166c770-1140-4564-abca-9ed2d165a684",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "annotated_results = cga_utils.annotate_results(res)\n",
    "#annotated_results.to_csv('res/Ollama_2_gemma3n_e4b_code_values_v11_m1.csv')\n",
    "cga_utils.calc_overall_value_match(annotated_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172b0b0d-c511-4c36-a99f-8273ce44dff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84b9692-191d-4789-898c-84d59e19e068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb63c2d3-3be2-4dff-a28e-18c29b74e3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cga_utils.calc_overall_em(annotated_results), cga_utils.calc_overall_em_alt(annotated_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c102fe96-a19c-4d35-98f2-f3d1814434a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_results.to_csv('res/gemma3_v19a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e1792c-680c-4d26-97f2-82e3d9f24726",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = annotated_results.query('error_code != \"none\"')\n",
    "cga_utils.crosstab_heatmap(df, 'error_code', 'calc_pattern', 40,0,3) \n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b53e9c-75bc-44a6-801b-0d6817487917",
   "metadata": {},
   "outputs": [],
   "source": [
    "v31 = pd.read_csv('res/e38_31.csv')\n",
    "cga_utils.compare_results(v31, annotated_results, \"qid\", \"exact_match\", [\"error_code\"]).to_csv('res/comp_v31_v45.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2ac17b-0d87-4f44-b6d7-d70be0180abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "messages = [(\"human\", \"Say Hi! /no_think\")]\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | llm | output_parser\n",
    "r = chain.invoke({})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b7757a-f8b5-46b9-9a0d-8c269e2621d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prompt_versions\n",
    "from fastapi import FastAPI\n",
    "import os\n",
    "from fastapi.responses import StreamingResponse\n",
    "from fastapi.staticfiles import StaticFiles\n",
    "from fastapi.responses import FileResponse\n",
    "from fastapi import Request\n",
    "\n",
    "import asyncio\n",
    "import json\n",
    "import ast\n",
    "import time\n",
    "import timeit\n",
    "from pathlib import Path\n",
    "\n",
    "import cga_utils\n",
    "import table_convert\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "llm = ChatOllama(model=\"qwen3:4b\", temperature = 0.0, top_p = 1, repeat_penalty=1, presence_penalty=0, frequency_penalty=0)  \n",
    "#agent = CodeGenAgent(llm, \"V38\")\n",
    "\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "messages = [(\"human\", \"Say Hi! /no_think\")]\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | llm | output_parser\n",
    "r = chain.invoke({})\n",
    "r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c11b94d-6b62-4fd0-b747-1cbf65cdce96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = annotated_results.query('error_code != \"none\"')\n",
    "cga_utils.crosstab_heatmap(df, 'error_code', 'calc_pattern', None, 0, 2)\n",
    "len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e809520-2846-4268-9118-dc838ad83ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fc1652-e376-4169-bf4b-5bc42c1cb7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cga_utils.crosstab_heatmap(df, 'error_code', 'calc_pattern', None, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430740b0-7d4f-46ff-971f-165e5cc28eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = annotated_results.query('error_code != \"none\"')\n",
    "cga_utils.crosstab_heatmap(df, 'error_code', 'aggr_calc_pattern', 40)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72563072-b31b-4600-b709-d0e99cb13052",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = annotated_results.query('error_code != \"none\"')\n",
    "cga_utils.crosstab_heatmap(df, 'error_code', 'calc_pattern', 40,0,3) \n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a28ffd7-e897-4b79-84f7-e3a2251a76a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "def crosstab_heatmap(df, x, y, vmax=None):\n",
    "    # 1. Kontingenciatábla\n",
    "    pattern_error_matrix = pd.crosstab(df[x], df[y], normalize='columns')\n",
    "    \n",
    "    # 3. Hőtérkép\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    sns.heatmap(pattern_error_matrix, cmap='YlOrBr', vmax=vmax, annot=True )\n",
    "    \n",
    "    #plt.title(\"Hibatípusok előfordulása számítási minták szerint (normalizálva)\")\n",
    "    plt.xlabel(y)\n",
    "    plt.ylabel(x)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "crosstab_heatmap(df, 'error_code', 'calc_pattern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d161a22d-62c2-443f-98b6-884be74fb72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def aggregate_calc_patterns(patterns, replacement=\"#\", other_group_szie=4):\n",
    "\n",
    "    def merge(text):        \n",
    "        while (f'{replacement}+{replacement}+{replacement}' in text):\n",
    "            text = text.replace(f'{replacement}+{replacement}+{replacement}', f'{replacement}+{replacement}')\n",
    "        return text\n",
    "    def aggr(text, counts):\n",
    "        if counts[text] > other_group_szie:\n",
    "            return text\n",
    "        else:\n",
    "            return \"other\"\n",
    "    merged = [merge(text) for text in texts]\n",
    "    counts = Counter(merged)\n",
    "    aggregated = [aggr(text, counts) for text in texts]\n",
    "    return aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db62a3f4-40f4-4b56-b756-56a3e6ec7e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = cga_utils.replace_numbers(annotated_results['derivation'])\n",
    "patterns2 = aggregate_calc_patterns(patterns)\n",
    "set(patterns2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adfcf03-68fb-486a-bb76-61aec769f3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = annotated_results.query('error_code != \"none\"')\n",
    "\n",
    "# 1. Csak a True/False típusú oszlopokat szűrjük ki\n",
    "bool_cols = df.select_dtypes(include=['bool'])\n",
    "\n",
    "# 2. Korrelációs mátrix számítása\n",
    "corr = bool_cols.corr()\n",
    "em_corr = bool_cols.corr()['exact_match'].dropna().sort_values(ascending=False)\n",
    "\n",
    "print(em_corr)\n",
    "\n",
    "# 3. Heatmap megjelenítés\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\", center=0)\n",
    "\n",
    "plt.title(\"Korrelációs heatmap (True/False oszlopokra)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c40ea69-c5b8-46b0-8104-6c9447c472d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4caad4-00cf-4cd8-8040-932faecdd092",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabular39",
   "language": "python",
   "name": "tabular39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
